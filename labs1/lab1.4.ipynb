{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глубокие нейронные сети для классификации изображений\n",
    "\n",
    "Вы будете использовать функции, которые вы реализовали в предыдущем задании, для построения глубокой сети и применять ее для классификации cat против non-cat. Вы увидите улучшение точности предсказания по сравнению с предыдущей реализацией логистической регрессии.\n",
    "\n",
    "**В рамках данной лабораторной работы будут приобретены следующие навыки:**\n",
    "- Создание и применение глубокой нейронной сети для обучения с учителем. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Данный материал опирается и использует материалы курса Deep Learning от организации deeplearning.ai`\n",
    " \n",
    " Ссылка на осной курс (для желающих получить сертификаты): https://www.coursera.org/specializations/deep-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Пакеты/Библиотеки ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первоначально необходимо запустить ячейку ниже, чтобы импортировать все пакеты, которые вам понадобятся во время лабораторной работы.\n",
    "- [numpy](www.numpy.org) является основным пакетом для научных вычислений в Python.\n",
    "- [h5py](http://www.h5py.org) это общий пакет для взаимодействия с набором данных, которые хранятся в файле H5.\n",
    "- [matplotlib](http://matplotlib.org) это пакет для отрисовки графиков в Python.\n",
    "- [PIL](http://www.pythonware.com/products/pil/) и [scipy](https://www.scipy.org/) используются здесь, чтобы проверить построенную модель с собственным (загруженным) изображением в конце лабораторной работы.\n",
    "- dnn_app_utils функции реализованные в предыдущей лабораторной работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from dnn_app_utils_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Датасет\n",
    "\n",
    "**Постановка задачи**: Дан набор данных (\"data.h5\") содержащий:\n",
    "    - обучающий набор m_train изображений рамеченных как cat (y=1) или non-cat (y=0);\n",
    "    - тестовый набор m_test изображений рамеченных как cat (y=1) или non-cat (y=0);\n",
    "    - каждое изображение имеет размер (num_px, num_px, 3) где 3 это 3 канала (RGB). Таким образом, каждое изображение это квадрат, где (height = num_px) и (width = num_px).\n",
    "\n",
    "Требуется построить прострой алгоритм, который сможет классифицировать объект на изображении (cat это или нет).\n",
    "\n",
    "Для того, чтобы познакомиться с набором данных, загрузите блок с кодом ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 24\n",
    "plt.imshow(train_x_orig[index])\n",
    "print (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = train_x_orig.shape[0]\n",
    "num_px = train_x_orig.shape[1]\n",
    "m_test = test_x_orig.shape[0]\n",
    "\n",
    "print (\"Количество обучающих примеров: \" + str(m_train))\n",
    "print (\"Количество тестовых примеров: \" + str(m_test))\n",
    "print (\"Каждое изображение имеет размер: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_x_orig shape: \" + str(train_x_orig.shape))\n",
    "print (\"train_y shape: \" + str(train_y.shape))\n",
    "print (\"test_x_orig shape: \" + str(test_x_orig.shape))\n",
    "print (\"test_y shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменение формы и стандартизация изображения перед подачей их в сеть. Код приведен в ячейке ниже.\n",
    "\n",
    "<img src=\"images/imvectorkiank.png\" style=\"width:450px;height:300px;\">\n",
    "\n",
    "<caption><center> <u>Рисунок 1</u> <br> </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменение размера обучающего и тестового множества примеров\n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "# Стандартизация\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "print (\"train_x's shape: \" + str(train_x.shape))\n",
    "print (\"test_x's shape: \" + str(test_x.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$12,288$ = $64 \\times 64 \\times 3$ размер вектора изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Архитектура модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В лабораторной работе необходимо построить 2 модели:\n",
    "- 2-слойнная нейронная сеть\n",
    "- L-слойнная глубокая нейронная сеть\n",
    "\n",
    "Затем необходимо будет сравнить производительность моделей, а также попробовать различные значения для $L$. \n",
    "\n",
    "### 3.1 - 2-слойнная нейронная сеть\n",
    "\n",
    "<img src=\"images/2layerNN_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "<caption><center> <u>Рисунок 2</u>: 2-слойнная нейронная сеть. <br> Модель выглядит вот так: ***INPUT -> LINEAR -> RELU -> LINEAR -> SIGMOID -> OUTPUT***. </center></caption>\n",
    "\n",
    "<u>Детализация архитектуры на Рисунке 2</u>:\n",
    "- Вход (64,64,3) изображение преобразованное в вектор размером $(12288,1)$. \n",
    "- Данный вектор: $[x_0,x_1,...,x_{12287}]^T$ затем умножается на матрицу весов $W^{[1]}$ размером $(n^{[1]}, 12288)$.\n",
    "- Затем добавляется смещение и вычисляете функцию активации, чтобы получить следующий вектор: $[a_0^{[1]}, a_1^{[1]},..., a_{n^{[1]}-1}^{[1]}]^T$.\n",
    "- Затем необходимо повторить данный процесс.\n",
    "- Результирующий вектор предыдущего слоя умножается на матрицу весов $W^{[2]}$ и добавляется смещение (bias). \n",
    "- В итоге, вычисляется sigmoid по выходу предыдущего слоя. Если значение больше 0.5, то изображение классифицируется как cat.\n",
    "\n",
    "### 3.2 - L-слойнаая глубокая нейронная сеть\n",
    "\n",
    "<img src=\"images/LlayerNN_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "<caption><center> <u>Рисунок 3</u>: L-слойнаая глубокая нейронная сеть. <br> Модель выглядит вот так: ***[LINEAR -> RELU] $\\times$ (L-1) -> LINEAR -> SIGMOID***</center></caption>\n",
    "\n",
    "<u>Детализация архитектуры на Рисунке 3</u>:\n",
    "- Вход (64,64,3) изображение преобразованное в вектор размером $(12288,1)$. \n",
    "- Данный вектор: $[x_0,x_1,...,x_{12287}]^T$ затем умножается на матрицу весов $W^{[1]}$ размером $(n^{[1]}, 12288)$ и добавляется смещение $b^{[1]}$. Результат называется линейной единицей измерения.\n",
    "- Далее производится расчёт функции активации RELU для линейного блока. Этот процесс можно повторить несколько раз для каждого слоя $(W^{[l]}, b^{[l]})$.\n",
    "- В итоге, вычисляется sigmoid по выходу предыдущего слоя. Если значение больше 0.5, то изображение классифицируется как cat.\n",
    "\n",
    "### 3.3 - Обобщённая методология\n",
    "Методика для построения модели глубокого обучения:\n",
    "    1. Инициализировать параметры\n",
    "    2. Цикл для num_iterations:\n",
    "        a. прямое распространение\n",
    "        б. Функция вычисления стоимости \n",
    "        c. обратное распространение\n",
    "        д. Параметры обновления (используя параметры, и градиенты из сеть с обратным распространением ошибки) \n",
    "    4. Используйте обученные параметры для прогнозирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - 2-слойнная нейронная сеть\n",
    "\n",
    "**Упражнение**: Используйте функции построенные в предыдущей лабораторной работе для построения 2-слойнной нейронной сети со следующей структурой: *LINEAR -> RELU -> LINEAR -> SIGMOID*. Функции, которые вам могут понадобиться, и их аргументы:\n",
    "```python\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    ...\n",
    "    return parameters \n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    ...\n",
    "    return A, cache\n",
    "def compute_cost(AL, Y):\n",
    "    ...\n",
    "    return cost\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    ...\n",
    "    return dA_prev, dW, db\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    ...\n",
    "    return parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Константы для построения модели ####\n",
    "n_x = 12288 # num_px * num_px * 3\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: two_layer_model\n",
    "\n",
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Реализация 2-х слойнной нейронной сети: LINEAR->RELU->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- матрица признаков (n_x, number of examples)\n",
    "    Y -- вектор меток (0 - cat, 1 - non-cat), размером (1, number of examples)\n",
    "    layers_dims -- размерность нейронной сети (n_x, n_h, n_y)\n",
    "    num_iterations -- количество итераций градиентного спуска\n",
    "    learning_rate -- скорость сходимости градиентного спуска\n",
    "    print_cost -- печать каждые 100 шагов\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- словарь с параметрами W1, W2, b1, и b2\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []  \n",
    "    m = X.shape[1] \n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    # Инициализируйте словарь параметров, вызвав одну из ранее реализованных функций\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 1 line of code)\n",
    "    parameters = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Прямое распространение: LINEAR -> RELU -> LINEAR -> SIGMOID. Вход: \"X, W1, b1\". Выход: \"A1, cache1, A2, cache2\".\n",
    "        ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 2 строки кода)\n",
    "        A1, cache1 = None\n",
    "        A2, cache2 = None\n",
    "        ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "        \n",
    "        # Расчёт потерь\n",
    "        ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 1 line of code)\n",
    "        cost = None\n",
    "        ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "        \n",
    "        # Запуска алгоритма обратного распространения\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        \n",
    "        # Обратное распространение. Вход: \"dA2, cache2, cache1\". Выход: \"dA1, dW2, db2; dA0, dW1, db1\".\n",
    "        ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 2 строки кода)\n",
    "        dA1, dW2, db2 = None\n",
    "        dA0, dW1, db1 = None\n",
    "        ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "        \n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        # Обновление параметров.\n",
    "        ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (approx. 1 line of code)\n",
    "        parameters = None\n",
    "        ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "\n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите ячейку ниже, чтобы обучить параметры. Проверьте, работает ли модель. Значение функции потерь должно уменьшаться. Для выполнения 2500 итераций может потребоваться до 5 минут. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = two_layer_model(train_x, train_y, layers_dims = (n_x, n_h, n_y), num_iterations = 2500, print_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**:\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Cost after iteration 0**</td>\n",
    "        <td> 0.6930497356599888 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 100**</td>\n",
    "        <td> 0.6464320953428849 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **...**</td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 2400**</td>\n",
    "        <td> 0.048554785628770206 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно использовать обученные параметры для классификации изображений из набора данных. Чтобы просмотреть прогнозы по наборам тренировок и тестов, запустите ячейку ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = predict(train_x, train_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**:\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Accuracy**</td>\n",
    "        <td> 1.0 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_test = predict(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**:\n",
    "\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Accuracy**</td>\n",
    "        <td> 0.72 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**: Можно заметить, что выполнение модели на меньшем количестве итераций (например, 1500) дает лучшую точность на тестовом наборе. Это называется \"ранняя остановка\". Ранняя остановка-это способ предотвратить переобучение.\n",
    "\n",
    "2-слойная нейронная сеть имеет лучшую точность (72%), чем реализация логистической регрессии (70%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - L-слойнаая глубокая нейронная сеть\n",
    "\n",
    "**Упражнение**: Используйте функции построенные в предыдущей лабораторной работе для построения $L$-слойнной нейронной сети со следующей структурой: *[LINEAR -> RELU]$\\times$(L-1) -> LINEAR -> SIGMOID*. Функции, которые вам могут понадобиться, и их аргументы:\n",
    "```python\n",
    "def initialize_parameters_deep(layer_dims):\n",
    "    ...\n",
    "    return parameters \n",
    "def L_model_forward(X, parameters):\n",
    "    ...\n",
    "    return AL, caches\n",
    "def compute_cost(AL, Y):\n",
    "    ...\n",
    "    return cost\n",
    "def L_model_backward(AL, Y, caches):\n",
    "    ...\n",
    "    return grads\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    ...\n",
    "    return parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Константы ###\n",
    "layers_dims = [12288, 20, 7, 5, 1] #  5-слойнная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: L_layer_model\n",
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Реализация L-х слойнной нейронной сети: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- матрица признаков (n_x, number of examples)\n",
    "    Y -- вектор меток (0 - cat, 1 - non-cat), размером (1, number of examples)\n",
    "    layers_dims -- размерность нейронной сети (number of layers + 1)\n",
    "    num_iterations -- количество итераций градиентного спуска\n",
    "    learning_rate -- скорость сходимости градиентного спуска\n",
    "    print_cost -- печать каждые 100 шагов\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- параметры модели, используемые для предсказания.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    \n",
    "    # Инициализация параметров.\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    parameters = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Прямое распространение: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 1 строка кода)\n",
    "        AL, caches = None\n",
    "        ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "        \n",
    "        # Расчёт потерь.\n",
    "        ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 1 строка кода)\n",
    "        cost = None\n",
    "        ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "        # Обратное распространение.\n",
    "        ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 1 строка кода)\n",
    "        grads = None\n",
    "        ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    " \n",
    "        # Обновление параметров.\n",
    "        ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 1 строка кода)\n",
    "        parameters = None\n",
    "        ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "                \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите ячейку ниже, чтобы обучить параметры. Проверьте, работает ли модель. Значение функции потерь должно уменьшаться. Для выполнения 2500 итераций может потребоваться до 5 минут. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**:\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Cost after iteration 0**</td>\n",
    "        <td> 0.771749 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 100**</td>\n",
    "        <td> 0.672053 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **...**</td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 2400**</td>\n",
    "        <td> 0.092878 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_train = predict(train_x, train_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "    <td>\n",
    "    **Train Accuracy**\n",
    "    </td>\n",
    "    <td>\n",
    "    0.985645933014\n",
    "    </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = predict(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**:\n",
    "\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Test Accuracy**</td>\n",
    "        <td> 0.8 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-слойная нейронная сеть имеет лучшую точность (80%), чем реализация 2-слойнной нейронной сети (72%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6 - Аналих результатов ##\n",
    "\n",
    "Во-первых, давайте взглянем на некоторые изображения, которые Модель L-слоями разметила неверно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mislabeled_images(classes, test_x, test_y, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Несколько типов изображений, которые модель плохо классифицирует:** \n",
    "- Тело кошки в необычном положении\n",
    "- Кошка появляется на фоне аналогичного цвета как и кошка\n",
    "- Необычный окрас и вид кошки\n",
    "- Яркость изображения\n",
    "- Изменение масштаба (кошка очень большая или маленькая на изображении)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Тестирование с вашими изображениями ##\n",
    "\n",
    "Вы можете использовать собственные изображения для тестирования разработанной модели. Что необходимо сделать:\n",
    "    1. Загрузите своё изображение в директорию /image/;\n",
    "    2. В коде ниже подставьте наименование изображения, соответствующее вашему;\n",
    "    3. Запустите алгоритм ниже (1 = cat, 0 = non-cat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ## (вставьте своё изображение) \n",
    "my_image = \"my_image.jpg\" # измените на имя своего изображения\n",
    "my_label_y = [1] # истинный класс изображения (1 -> cat, 0 -> non-cat)\n",
    "## ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ##\n",
    "\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px*num_px*3,1))\n",
    "my_predicted_image = predict(my_image, my_label_y, parameters)\n",
    "\n",
    "plt.imshow(image)\n",
    "print (\"y = \" + str(np.squeeze(my_predicted_image)) + \", модель предсказала \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" изображение.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Используемый материал:**:\n",
    "- Курс Deep Learning; https://www.coursera.org/specializations/deep-learning\n",
    "- for auto-reloading external module: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "TSPse",
   "launcher_item_id": "24mxX"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
