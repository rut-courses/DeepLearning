{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия как структурная часть нейронной сети\n",
    "\n",
    "В рамках данной лабораторной работы необходимо будет создать модель на основе логистической регрессии по распознаванию кошек на изображении.\n",
    "Данная работа является пошаговым руководством по созданию классификатора на базе логистической регрессии в контексте построения моделей машинного обучения.\n",
    "\n",
    "**Инструкции:**\n",
    "- Запрещено использовать циклы (for/while) в коде, за исключением тех случаев, где это явно не прописано в условии задачи.\n",
    "\n",
    "**В рамках данной лабораторной работы будут приобретены следующие навыки (знания):**\n",
    "   - Принципы построения алгоритма машинного обучения, в частности:\n",
    "    - инициализация параметров;\n",
    "    - вычисление функции потерь и его градиента;\n",
    "    - использовать алгоритм оптимизации (градиентный спуск).\n",
    "   - Принципы сбора всех частей алгоритма в единую (главную) функцию в правильной последовательности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Данный материал опирается и использует материалы курса Deep Learning от организации deeplearning.ai`\n",
    " \n",
    " Ссылка на основной курс (для желающих получить дополнительный сертификаты): https://www.coursera.org/specializations/deep-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Пакеты/Библиотеки ##\n",
    "\n",
    "Первоначально необходимо запустить ячейку ниже, чтобы импортировать все пакеты, которые вам понадобятся во время лабораторной работы.\n",
    "- [numpy](www.numpy.org) является основным пакетом для научных вычислений в Python.\n",
    "- [h5py](http://www.h5py.org) это общий пакет для взаимодействия с набором данных, которые хранятся в файле H5.\n",
    "- [matplotlib](http://matplotlib.org) это пакет для отрисовки графиков в Python.\n",
    "- [PIL](https://pillow.readthedocs.io/en/stable/) и [scipy](https://www.scipy.org/) используются здесь, чтобы проверить построенную модель с собственным (загруженным) изображением в конце лабораторной работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from lr_utils import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2 - Постановка задачи ##\n",
    "\n",
    "Дан набор данных (\"data.h5\") содержащий:\n",
    "    - обучающий набор `m_train` изображений размеченных как `cat` (`y=1`) или `non-cat` (`y=0`);\n",
    "    - тестовый набор `m_test` изображений размеченных как `cat` (`y=1`) или `non-cat` (`y=0`);\n",
    "    - каждое изображение имеет размер (`num_px`, `num_px`, `3`) где `3` это количество каналов (RGB). Таким образом, каждое изображение это квадрат, где (`height = num_px`) и (`width = num_px`).\n",
    "\n",
    "Требуется построить прострой алгоритм, который сможет классифицировать объект на изображении (`cat` это или `non-cat`).\n",
    "\n",
    "Для того чтобы познакомиться с набором данных, загрузите блок с кодом ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/j9/53xfzg7543v3phx1kg960fp80000gn/T/ipykernel_24646/1860602961.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Загрузка данных\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtrain_set_x_orig\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_set_y\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_set_x_orig\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_set_y\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclasses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая строка в обучающем (`train_set_x_orig`) и тестовом (`test_set_x_orig`) массиве данных является изображением.\n",
    "Следующий блок с кодом визуализирует изображение.\n",
    "Попробуйте поменять индекс массива, чтобы посмотреть различные примеры изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/j9/53xfzg7543v3phx1kg960fp80000gn/T/ipykernel_24646/3139602825.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Пример изображения\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m14\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_set_x_orig\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m print (\"y = \" + str(train_set_y[:, index]) + \", Это '\" \n\u001B[1;32m      5\u001B[0m        + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' на изоражении.\")\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Пример изображения\n",
    "index = 14\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \", Это '\" \n",
    "       + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' на изоражении.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Множество ошибок в глубоком обучении имеет причину, связанную с неверным использованием размеров матриц/векторов при выполнении операции с ними.\n",
    "\n",
    "**Упражнение**\n",
    "\n",
    "Найдите значения для:\n",
    "    - `m_train` (количество обучающих примеров)\n",
    "    - `m_test` (количество тестовых примеров)\n",
    "    - `num_px` (`height = width` изображения из обучающего массива)\n",
    "Напоминание: `train_set_x_orig` это numpy-array размером (`m_train`, `num_px`, `num_px`, `3`).\n",
    "Например, для того, чтобы получить доступ к первой размерности `m_train` необходимо написать `train_set_x_orig.shape[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 3 строки кода)\n",
    "m_train = None\n",
    "m_test = None\n",
    "num_px = None\n",
    "### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "\n",
    "print (\"Количество обучающих примеров: m_train = \" + str(m_train))\n",
    "print (\"Количество тестовых примеров: m_test = \" + str(m_test))\n",
    "print (\"Height/Width для каждого изображения: num_px = \" + str(num_px))\n",
    "print (\"Каждое изображение имеет размер: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат для m_train, m_test и num_px**: \n",
    "<table style=\"width:20%\">\n",
    "  <tr>\n",
    "    <td>**m_train**</td>\n",
    "    <td> 209 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**m_test**</td>\n",
    "    <td> 50 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**num_px**</td>\n",
    "    <td> 64 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства можно преобразовать размер изображения (`num_px`, `num_px`, `3`) в массив numpy-array размером (num_px $*$ num_px $*$ 3, 1).\n",
    "После этого обучающее (тестовое) изображение в виде numpy-array представляет собой flattened (вытянутое/сплющенное) изображение.\n",
    "\n",
    "**Упражнение**\n",
    "\n",
    "Необходимо изменить размеры обучающего и тестового набора данных таким образом,\n",
    "чтобы из матрицы размером (`num_px`, `num_px`, `3`) получился вектор (num\\_px $*$ num\\_px $*$ 3, 1).\n",
    "\n",
    "Если есть потребность сделать преобразование изображения (матрицы) X размером (a,b,c,d) в вектор X_flatten размером (b$*$c$*$d, a), то можно использовать: \n",
    "```python\n",
    "X_flatten = X.reshape(X.shape[0], -1).T      # X.T это операция транспонирования X\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Измените размер обучающего и тестового множества примеров\n",
    "\n",
    "### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 2 строки кода)\n",
    "train_set_x_flatten = None\n",
    "test_set_x_flatten = None\n",
    "### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**: \n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td>**train_set_x_flatten shape**</td>\n",
    "    <td> (12288, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**train_set_y shape**</td>\n",
    "    <td>(1, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**test_set_x_flatten shape**</td>\n",
    "    <td>(12288, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**test_set_y shape**</td>\n",
    "    <td>(1, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>**sanity check after reshaping**</td>\n",
    "  <td>[17 31 56 22 33]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для представления цветных изображений используется красный, зеленый и синий каналы (RGB),\n",
    "которые представляют собой вектор из трех чисел (пикселей) в диапазоне от 0 до 255.\n",
    "\n",
    "Один из общих и основных шагов в машинном обучении это центрирование и стандартизация датасета.\n",
    "Это означает вычитание среднего из каждого элемента массива и затем деление на стандартное отклонение по всем элементам.\n",
    "Но для датасета из изображений применяется немного другой метод, который заключается в делении каждого элемента на 255 (это максимальное значение пикселя).\n",
    "\n",
    "<!-- Во время обучения модели вы будете умножать веса и добавлять смещения к некоторым начальным входам, чтобы наблюдать за активациями нейронов.\n",
    "Затем для обучения модели требуется вычислить градиенты. Но для каждого объекта крайне важно иметь одинаковый диапазон, чтобы наши градиенты не \"взрывались\".\n",
    "Вы увидите это более подробно позже в лекциях!-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**Что нужно помнить:**\n",
    "\n",
    "Общие шаги для предварительной обработки нового набора данных:\n",
    "- Выяснить размеры и формы изображений для решаемой задачи (`m_train`, `m_test`, `num_px`, ...)\n",
    "- Измените наборы данных таким образом, чтобы каждый пример представлял собой вектор размера (num_px \\* num_px \\* 3, 1)\n",
    "- \"Стандартизовать\" данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Основной процесс построения обучающего алгоритма ##\n",
    "\n",
    "Далее необходимо разработать простой алгоритм, умеющий различать изображения с `cat` от изображений `non-cat`.\n",
    "\n",
    "Используемая модель: логистическая регрессия как структурная составляющая нейронной сети.\n",
    "На следующем рисунке дано объяснение связи между логистической регрессией и нейронной сетью.\n",
    "\n",
    "**Логистическая регрессия, как очень простая нейронная сеть!**\n",
    "\n",
    "<img src=\"images/LogReg_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "\n",
    "**Математическое объяснение алгоритма**:\n",
    "\n",
    "Для одного примера $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "Функция потерь вычисляется как сумма для всех обучающих примеров:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "**Ключевые шаги**:\n",
    "В рамках данной лабораторной работы необходимо сделать следующие ключевые шаги: \n",
    "    - инициализация параметров модели;\n",
    "    - подбор параметров модели, соответствующие минимуму функции потерь;\n",
    "    - использование полученных параметров для предсказания (на тестовой выборке);\n",
    "    - анализ результатов и выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Строим по частям алгоритм ##\n",
    "\n",
    "Главными шагами в построении простой нейронной сети является:\n",
    "1. Определение структуры модели (например количество входных признаков).\n",
    "2. Инициализация параметров модели.\n",
    "3. Цикл:\n",
    "    - вычисление текущих значений функции потерь (forward propagation)\n",
    "    - вычисление текущих градиентов (backward propagation)\n",
    "    - обновление параметров (gradient descent)\n",
    "\n",
    "Достаточно часто отдельно готовятся три функции, соответствующие 3-м предыдущим шагам, а только затем создается обобщающая функция `model()`.\n",
    "\n",
    "### 4.1 - Функции - помощники\n",
    "\n",
    "**Упражнение** Используя основы Python, разработайте функцию `sigmoid()`.\n",
    "\n",
    "Как вы видели на рисунке выше, вам необходимо вычислить $sigmoid( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}$. Используйте np.exp()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Вычисление sigmoid от z\n",
    "\n",
    "    Arguments:\n",
    "    z -- скаляр или числовой массив любого размера\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    s = None\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 1 строка кода)\n",
    "    \n",
    "    \n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**: \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>**sigmoid([0, 2])**</td>\n",
    "    <td> [ 0.5         0.88079708]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Инициализация параметров\n",
    "\n",
    "**Упражнение** Инициализируйте параметры запустив ячейку ниже.\n",
    "Необходимо инициализировать веса `w` как вектор нулей.\n",
    "Если вы не знаете функции в numpy, которая это выполняет, то посмотрите как работает функция np.zeros() в документации Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: initialize_with_zeros\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    Эта функция создает вектор нулей размером (dim, 1) для весов w и инициализирует b как 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- размер вектора весов w (или количество признаков, подаваемых на вход)\n",
    "    \n",
    "    Returns:\n",
    "    w -- инициализированный вектор весов (weights) размеров (dim, 1)\n",
    "    b -- инициализорованный скаляр (bias)\n",
    "    \"\"\"\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 2 строки кода)\n",
    "    w = None\n",
    "    b = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**: \n",
    "\n",
    "\n",
    "<table style=\"width:15%\">\n",
    "    <tr>\n",
    "        <td>  ** w **  </td>\n",
    "        <td> [[ 0.]\n",
    " [ 0.]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** b **  </td>\n",
    "        <td> 0 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Для каждого входного изображения, w должно иметь размер (num_px $\\times$ num_px $\\times$ 3, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Прямое (forward) и Обратное (backward) распространение \n",
    "\n",
    "Теперь, когда параметры инициализированы, можно выполнить шаги \"forward\" и \"backward\" распространения для подбора параметров.\n",
    "\n",
    "**Упражнение** Реализовать функцию `propagate()` которая вычисляет функция потерь (cost function) и его градиент.\n",
    "\n",
    "**Подсказка**:\n",
    "\n",
    "Прямое распространение:\n",
    "- Получаете X\n",
    "- Вычисляете $A = \\sigma(w^T X + b) = (a^{(0)}, a^{(1)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- Вычисляете функцию потерь: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
    "\n",
    "Ниже написаны формулы, которые можно использовать для вычисления градиента:\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: propagate\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Реализуйте функцию потерь и её градиент для распространений описанных выше\n",
    "\n",
    "    Arguments:\n",
    "    w -- веса(weights), numpy массив размером (num_px * num_px * 3, 1)\n",
    "    b -- смещение(bias), скаляр\n",
    "    X -- данные размером (num_px * num_px * 3, number of examples)\n",
    "    Y -- вектор меток \"label\" (содержащий 0 \"non-cat\", 1 если \"cat\") размером (1, количество примеров)\n",
    "\n",
    "    Return:\n",
    "    cost -- значение функции потерь для логистической регрессии\n",
    "    dw -- градиент для весов w, размер совпадает с размером вектора весов w\n",
    "    db -- градиент для смещений b, размер совпадает с размером смещения b\n",
    "    \n",
    "    Подсказка:\n",
    "    - Можно использовать функции: np.log(), np.dot()\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # прямое распространение\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 2 строки кода)\n",
    "    A = None # функция активации\n",
    "    cost = None # функция потерь\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    # обратное распространение\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 2 строки кода)\n",
    "    dw = None\n",
    "    db = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b, X, Y = np.array([[1],[2]]), 2, np.array([[1,2],[3,4]]), np.array([[1,0]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**:\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <td>  ** dw **  </td>\n",
    "        <td> [[ 0.99993216]\n",
    " [ 1.99980262]]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** db **  </td>\n",
    "        <td> 0.499935230625 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** cost **  </td>\n",
    "        <td> 6.000064773192205</td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация\n",
    "- У вас реализована инициализация параметров.\n",
    "- Вы реализовали функцию, которая вычисляет функцию потерь и его градиент.\n",
    "- В следующем упражнении необходимо реализовать градиентный спуск, который будет обновлять значения функции потерь и его градиентов.\n",
    "\n",
    "**Упражнение:** Реализуйте функцию градиентного спуска. \n",
    "Цель состоит в том, чтобы обучить параметры $w$ и $b$ минимизируя функцию потерь $J$. Для параметра $\\theta$, правилом обновления является $ \\theta = \\theta - \\alpha \\text{ } d\\theta$, где $\\alpha$ скорость обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    Функция оптимизации w и b и запуск алгоритма градиентого спуска\n",
    "    \n",
    "    Arguments:\n",
    "    w -- веса(weights), numpy массив размером (num_px * num_px * 3, 1)\n",
    "    b -- смещение(bias), скаляр\n",
    "    X -- данные размером (num_px * num_px * 3, number of examples)\n",
    "    Y -- вектор меток \"label\" (содержащий 0 \"non-cat\", 1 если \"cat\") размером (1, количество примеров)\n",
    "    num_iterations -- количество итерация обучения\n",
    "    learning_rate -- скорость/длина шага по градиенту\n",
    "    print_cost -- True печать каждые 100 шагов\n",
    "    \n",
    "    Returns:\n",
    "    params -- словарь, содержащий веса w и смещения b\n",
    "    grads  -- словарь, содержащий градиенты весов и смещений относительно функции стоимости\n",
    "    costs  -- список значений функции потерь, рассчитанных во время оптимизации,\n",
    "              будет использован для построения кривой обучения.\n",
    "    \n",
    "    Подсказка:\n",
    "    Для реализации алгоритма градиентного спуска необходимо выполнить два шага:\n",
    "        1) Рассчитать значение функции потерь и градиент для текущих параметров. Используйте propagate().\n",
    "        2) Обновите параметры, используя правило градиентного спуска для w и b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        # Вычисление значения функции потерь и градиентов (≈ 1-4 строки кода)\n",
    "        ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### \n",
    "        grads, cost = None\n",
    "        ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "        \n",
    "        # Запись производных\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # Правило обновления (≈ 2 строки кода)\n",
    "        ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ###\n",
    "        w = None\n",
    "        b = None\n",
    "        ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "        \n",
    "        # Запись значения функции потерь\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Печать каждые 100 обучающих примеров\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost после итерации %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**: \n",
    "\n",
    "<table style=\"width:40%\">\n",
    "    <tr>\n",
    "       <td> **w** </td>\n",
    "       <td>[[ 0.1124579 ], [ 0.23106775]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **b** </td>\n",
    "       <td> 1.55930492484 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **dw** </td>\n",
    "       <td> [[ 0.90158428], [ 1.76250842]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **db** </td>\n",
    "       <td> 0.430462071679 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Упражнение** Предыдущая функция выведет подобранные w и b. Вы можете использовать w и b, чтобы предсказать метки для набора данных X. Реализуйте функцию `predict()`. Есть два шага для вычисления прогнозов:\n",
    "\n",
    "1. Вычислите $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. Конвертировать записи в 0 (если функция активации <= 0.5) или 1 (если функция активации > 0.5), сохранять прогнозы в векторе `Y_prediction`. Если вы хотите, вы можете использовать `if`/`else` выражение в `for` цикле (хотя есть также способ векторизации). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Предсказание параметров, будет ли метка 0 или 1, используя обученные параметры логистической регрессии (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- веса(weights), numpy массив размером (num_px * num_px * 3, 1)\n",
    "    b -- смещение(bias), скаляр\n",
    "    X -- данные размером (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- numpy массив (вектор) содержащий предсказания (0/1) для примеров в матрице X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Вычислить вектор «A», предсказывающий вероятности присутствия cat на снимке\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 1 строка кода)\n",
    "    A = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Конвертировать вероятности A[0,i] к реальным прогнозам p[0,i]\n",
    "        ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (≈ 4 строки кода)\n",
    "\n",
    "        \n",
    "        ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"предсказания = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**: \n",
    "\n",
    "<table style=\"width:30%\">\n",
    "    <tr>\n",
    "         <td>\n",
    "             **predictions**\n",
    "         </td>\n",
    "          <td>\n",
    "            [[ 1.  1.]]\n",
    "         </td>  \n",
    "   </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color='blue'>\n",
    "\n",
    "**Что необходимо помнить:**\n",
    "\n",
    "Вы реализовали несколько функций, которые выполняют:\n",
    "\n",
    "- инициализацию (w,b)\n",
    "- итеративную оптимизацию функции потерь для обучения параметров (w,b):\n",
    "    - вычисление функции потерь и его градиентов \n",
    "    - обновление параметров с использованием градиентного спуска\n",
    "- предсказание метки для данного набора примеров на основе обученных (w,b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Объединить все функции в модель ##\n",
    "\n",
    "Теперь вы увидите, как структурируется общая модель, собрав вместе все строительные блоки (функции, реализованные в предыдущих частях) в правильном порядке.\n",
    "\n",
    "**Упражнение** Реализуйте функцию модели. Используйте следующие обозначения:\n",
    "    - `Y_prediction` для прогнозов на тестовом наборе\n",
    "    - `Y_prediction_train` для прогнозов на обучающем наборе\n",
    "    - `w`, `costs`, `grads` для выходов функции оптимизации `optimize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    Создает модель логистической регрессии, вызывая функции, которые вы реализовали ранее \n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- обучающий набор, представленный numpy массивом размером (num_px * num_px * 3, m_train)\n",
    "    Y_train -- метки для обучения преставлены numpy массивом (вектором) размером (1, m_train)\n",
    "    X_test -- тестовый набор, представленный numpy массивом размером  (num_px * num_px * 3, m_test)\n",
    "    Y_test -- метки для тестирования преставлены numpy массивом (вектором) размером (1, m_test)\n",
    "    num_iterations -- гиперпараметр, представляющий количество интераций оптимизации параметров\n",
    "    learning_rate -- гиперпараметр, представляющий скорость обучения/длину градиентного шага для функции optimize()\n",
    "    print_cost -- печать каждые 100 шагов\n",
    "    \n",
    "    Returns:\n",
    "    d -- словарь, содержащий информацию о модели.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    # Инициализируйте параметры (≈ 1 строка кода)\n",
    "    w, b = None\n",
    "\n",
    "    # Градиентный спуск (≈ 1 строка кода)\n",
    "    parameters, grads, costs = None\n",
    "    \n",
    "    # Запись производных в словарь \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Предсказание test/train для набора примеров (≈ 2 строки кода)\n",
    "    Y_prediction_test = None\n",
    "    Y_prediction_train = None\n",
    "\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "\n",
    "    # Печать точности (accuracy) неверных предсказаний на train/test наборах\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите следующую ячейку, чтобы обучить вашу модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, \n",
    "          num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**: \n",
    "\n",
    "<table style=\"width:40%\">   \n",
    "    <tr>\n",
    "        <td> **Train Accuracy**  </td> \n",
    "        <td> 99.04306220095694 % </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>**Test Accuracy** </td> \n",
    "        <td> 70.0 % </td>\n",
    "    </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Комментарий**: Точность на обучающей выборке близка к 100%. Ошибка на тестовой выборке составляет 70%. Это на самом деле неплохо для этой модели, учитывая небольшой набор данных, который мы использовали, и то, что логистическая регрессия достаточно простая модель.\n",
    "\n",
    "Также вы можете наблюдать эффект переобучения (overfitting). \n",
    "\n",
    "Используя приведенный ниже код (и изменяя переменную `index`) вы можете посмотреть прогнозы на рисунках тестового набора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 15\n",
    "plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))\n",
    "print (\"y = \" + str(test_set_y[0,index]) + \", ваше предсказание, что это класс \" + \n",
    "       classes[int(d[\"Y_prediction_test\"][0,index])].decode(\"utf-8\") +  \" на изображении.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте также построим функцию стоимости и градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('Итерации (деленное на 100)')\n",
    "plt.title(\"Длина градиентного шага =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Интерпретация**:\n",
    "\n",
    "Вы можете увидеть снижение стоимости. Это показывает, что параметры обучаются. Однако вы видите, что можете тренировать модель еще дольше на обучающей выборке. Попробуйте увеличить количество итераций в ячейке выше, и перезапустите ячейки. Вы можете видеть, что точность тренировочного набора повышается, но точность тестового набора снижается. Это называется переобучением (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Дальнейший анализ ##\n",
    "\n",
    "Давайте проанализируем работу модели и рассмотрим возможные варианты для скорости обучения $\\alpha$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выбор скорости обучения ####\n",
    "\n",
    "**Напоминание**:\n",
    "Для того, чтобы Gradient Descent работал, вы должны грамотно выбирать скорость обучения. Скорость обучения $\\alpha$ определяет, насколько быстро обновляются параметры. Если скорость обучения слишком велика, мы можем «перешагнуть» оптимальное значение. Точно так же, если она слишком мал, нам потребуется слишком много итераций, чтобы сходиться к лучшим значениям. Вот почему важно использовать хорошо настроенную скорость обучения.\n",
    "\n",
    "Давайте сравним кривую обучения нашей модели с несколькими вариантами обучения. Запустите ячейку ниже. Это должно занять около 1 минуты. Не стесняйтесь также попробовать значения, отличные от трех, которые инициализированные в примере для переменной `learning_rates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    print (\"Скорость обучения: \" + str(i))\n",
    "    models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "\n",
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(i)][\"costs\"]), label= str(models[str(i)][\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Интерпретация**: \n",
    "- Разные значения скорости обучения дают разные значения функции потерь и, следовательно, разные результаты прогнозов.\n",
    "- Если скорость обучения значительно большое (0.01), значение функции потерь может колебаться, то вверх, то вниз. Значение функции потерь даже может расходиться.\n",
    "- Более маленькое значение функции потерь не означает лучшую модель. Вы должны проверить, возможно ли переобучение. Это происходит, когда точность на обучающей выборке намного выше, чем точность на тестовой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 7 - Тестирование с вашими изображениями ##\n",
    "\n",
    "Вы можете использовать собственные изображения для тестирования разработанной модели. Что необходимо сделать:\n",
    "    1. Загрузите своё изображение в директорию /image/;\n",
    "    2. В коде ниже подставьте наименование изображения, соответствующее вашему;\n",
    "    3. Запустите алгоритм ниже (1 = `cat`, 0 = `non-cat`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ## (вставьте своё изображение) \n",
    "my_image = \"my_image.jpg\"   # измените на имя своего изображения\n",
    "## ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ##\n",
    "\n",
    "# Предобработка изображения и передача его в алгоритм.\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((1, num_px*num_px*3)).T\n",
    "my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", модель предсказала \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**Что необходимо запомнить:**\n",
    "\n",
    "1. Предварительная обработка набора данных необходима.\n",
    "2. Реализации каждой функции в отдельности: `initialize()`, `propagate()`, `optimize()`. Затем построение модели `model()`.\n",
    "3. Настройка скорости обучения (которая является гиперпараметром - \"hyperparameter\") являтся важным аспектом обучения, так как она может привести к различным результатам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможности для экспериментов:\n",
    "  - Изменение скорости обучения и количество итераций\n",
    "  - Попробуйте разные методы инициализации и сравните результаты.\n",
    "  - Проверьте другие предварительные обработки (центрируйте данные или разделите каждую строку по ее стандартному отклонению)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используемый материал:\n",
    "- Курс Deep Learning; https://www.coursera.org/specializations/deep-learning\n",
    "- http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n",
    "- https://stats.stackexchange.com/questions/211436/why-do-we-normalize-images-by-subtracting-the-datasets-image-mean-and-not-the-c"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}