{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Networks\n",
    "\n",
    "В рамках данной лабораторной работа разбирается принцип построения очень глубоких сверточных сетей, используя остаточные сети (Resnet). Теоретически очень глубокие сети могут представлять очень сложные функции, но на практике их трудно обучить. Остаточные сети, введенные [He et al.](http://arxiv.org/pdf/1512.03385.pdf), позволяют тренировать гораздо более глубокие сети, чем это было ранее практически осуществимо.\n",
    "\n",
    "**В данной работе:**\n",
    "- Реализуете основные строительные блоки ResNets. \n",
    "- Соберёте вместе эти строительные блоки, чтобы реализовать и обучить нейронную сеть для классификации изображений. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Данный материал опирается и использует материалы курса Deep Learning от организации deeplearning.ai`\n",
    " \n",
    " Ссылка на основной курс (для желающих получить сертификаты): https://www.coursera.org/specializations/deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Проблемы с очень глубокими нейронными сетями\n",
    "\n",
    "В последние годы нейронные сети стали более глубокими, причем современные сети переходят от всего лишь нескольких слоев (например, AlexNet) к более чем сотне слоев.\n",
    "\n",
    "* Главное преимущество очень глубокой сети заключается в том, что она может представлять очень сложные функции. Он также может изучать объекты на многих различных уровнях абстракции, от краев (на более мелких слоях, ближе к входу) до очень сложных объектов (на более глубоких слоях, ближе к выходу).\n",
    "* Однако использование более глубокой сети не всегда помогает. Огромным препятствием для их обучения является исчезновение градиентов: очень глубокие сети часто имеют градиентный сигнал, который быстро идет к нулю, что делает градиентный спуск слишком медленным.\n",
    "* Более конкретно, во время градиентного спуска, когда вы возвращаетесь от конечного слоя обратно к первому слою, вы умножаете весовую матрицу на каждом шаге, и таким образом градиент может быстро уменьшаться экспоненциально до нуля (или, в редких случаях, быстро расти экспоненциально и \"взрываться\", принимая очень большие значения).\n",
    "* Таким образом, во время тренировки вы можете увидеть, что величина (или норма) градиента для более мелких слоев очень быстро уменьшается до нуля по мере продолжения тренировки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/vanishing_grad_kiank.png\" style=\"width:450px;height:220px;\">\n",
    "<caption><center> <u> <font color='purple'>**Рисунок 1**</u><font color='purple'>  : **Исчезновение градиентов** <br> Скорость обучения снижается очень быстро для более мелких слоев по мере развития сети</center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Построение Residual Network\n",
    "\n",
    "В ResNets \"shortcut\" или \"skip connection\" позволяет модели пропускать слои:\n",
    "<img src=\"images/skip_connection_kiank.png\" style=\"width:650px;height:200px;\">\n",
    "<caption><center> <u> <font color='purple'>**Рисунок 2**</u><font color='purple'>  : ResNet блок - **skip-connection** <br> </center></caption>\n",
    "\n",
    "Изображение слева показывает \"основной путь\" через сеть. Изображение справа добавляет ярлык к основному пути. Укладывая эти блоки ResNet друг на друга, вы можете сформировать очень глубокую сеть.\n",
    "\n",
    "Наличие блоков ResNet с ярлыком очень облегчает для одного из блоков изучение функции идентификации. Это означает, что вы можете накапливать дополнительные блоки ResNet с небольшим риском ухудшения производительности обучающего набора.\n",
    "\n",
    "В Сети ResNet используются два основных типа блоков в зависимости от того, одинаковы или различны размеры input/output: \"identity block\" и \"convolutional block\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Identity block (блок идентификации)\n",
    "\n",
    "Блок идентификации это стандартный блок используемый в ResNet, и соответствует тому случаю, когда input activation ($a^{[l]}$) имеет такой же размер output activation ($a^{[l+2]}$). Чтобы конкретизировать различные шаги того, что происходит в блоке идентификации ResNet, вот альтернативная диаграмма, демонстрирующая отдельные шаги:\n",
    "<img src=\"images/idblock2_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Рисунок 3** </u><font color='purple'>  : **Identity block.** Пропуск соединения \"пропускает\" 2 слоя.</center></caption>\n",
    "\n",
    "Верхний путь - это \"кратчайший путь\". Нижний путь- это \"главный путь\". На этой диаграмме представлены явными шаги CONV2D и ReLU в каждом слое. Чтобы ускорить обучение, мы также добавили шаг BatchNorm.\n",
    "\n",
    "В этом упражнении необходимо реализовать несколько более мощную версию этого блока идентификации, в которой соединение пропуска 3 скрытых слоя, а не 2 слоя. Это выглядит примерно так:\n",
    "\n",
    "<img src=\"images/idblock3_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Рисунок 4** </u><font color='purple'>  : **Identity block.** Пропускает 3 слоя.</center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот отдельные шаги.\n",
    "\n",
    "Первый компонент - главный путь: \n",
    "- Первый CONV2D имеет $F_1$ фильтров размером (1,1) и шагом (1,1). Padding - \"valid\" и имя слоя корректно дать `conv_name_base + '2a'`.\n",
    "- BatchNorm - нормализация 'channels' размерности.  Имя слоя - `bn_name_base + '2a'`.\n",
    "- Затем ReLU activation function. Которая не имеет имя и гиперпараметры. \n",
    "\n",
    "Второй компонент - главный путь:\n",
    "- Второй CONV2D имеет $F_2$ ильтров размером $(f,f)$ и шагом (1,1).  Padding - \"same\" и имя слоя корректно дать `conv_name_base + '2b'`.\n",
    "- BatchNorm - нормализация 'channels' размерности.  Имя слоя - `bn_name_base + '2b'`.\n",
    "- Затем ReLU activation function. Которая не имеет имя и гиперпараметры. \n",
    "\n",
    "Третий компонент - главный путь:\n",
    "- Третий CONV2D имеет $F_3$ фильтров размером (1,1) и шагом (1,1). Padding - \"valid\" и имя слоя корректно дать `conv_name_base + '2c'`.\n",
    "- BatchNorm - нормализация 'channels' размерности.  Имя слоя - `bn_name_base + '2c'`. \n",
    "- **Нет** ReLU activation function в данном компоненте. \n",
    "\n",
    "Конечный шаг: \n",
    "- `X_shortcut` и выход из 3-го слоя `X` сложенные вместе.\n",
    "- **Подсказка**: Синтаксис `Add()([var1,var2])`\n",
    "- Затем ReLU activation function. Которая не имеет имя и гиперпараметры. \n",
    "\n",
    "**Упражнение**: Реализовать ResNet identity block. Первый компонент главного пути уже реализован. Пожалуйста, прочтите внимательно, чтобы убедиться, что вы понимаете, что он делает. Вы должны реализовать все остальное.\n",
    "- Реализовать Conv2D: [Conv2D](https://keras.io/layers/convolutional/#conv2d)\n",
    "- Реализовать BatchNorm: [BatchNormalization](https://faroit.github.io/keras-docs/1.2.2/layers/normalization/)\n",
    "- Реализовать функцию активации:  `Activation('relu')(X)`\n",
    "- Сложить два входа: [Add](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: identity_block\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Реализовать identity block представленный на Рисунке 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- целое число, задающее форму окна CONV для главного пути    \n",
    "    filters -- python список integers, определяющих количество фильтров в слоях CONV основного пути\n",
    "    stage -- integer, используется для наименования слоев в зависимости от их положения в сети\n",
    "    block -- string/character, используется для наименования слоев в зависимости от их положения в сети\n",
    "    \n",
    "    Returns:\n",
    "    X -- выход identity block, размером (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # определение пространства имён\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Извлечение фильтров\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Сохраните входное значение. Это понадобится позже, чтобы добавить обратно в основной путь. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # Первый шаг - главный путь\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### НАЧАЛО ВАШЕГО КОД ###\n",
    "    \n",
    "    # Второй шаг главного пути (≈3 строки кода)\n",
    "    X = None\n",
    "    X = None\n",
    "    X = None\n",
    "\n",
    "    # Третьий шаг главного пути (≈2 строки кода)\n",
    "    X = None\n",
    "    X = None\n",
    "\n",
    "    # Финальный шаг: Добавьте shortcut значение в главный путь и пропустите через RELU активацию (≈2 строки кода)\n",
    "    X = None\n",
    "    X = None\n",
    "    \n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ###\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый выход**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **out**\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.94822985  0.          1.16101444  2.747859    0.          1.36677003]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Сonvolutional block (блок свёртки)\n",
    "\n",
    "ResNet \"сверточный блок\" - это второй тип блока. Вы можете использовать этот тип блока, когда input и output размеры не совпадают. Разница с блоком идентификации заключается в том, что в кратчайшем пути есть CONV2Dlayer:\n",
    "\n",
    "<img src=\"images/convblock_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Рисунок 4** </u><font color='purple'>:**Convolutional block**</center></caption>\n",
    "\n",
    "* Слой CONV2D в пути быстрого доступа используется для изменения размера входных данных $x$ в другое измерение, чтобы размеры совпадали в конечном добавлении, необходимом для добавления значения быстрого доступа обратно в основной путь.\n",
    "* Например, чтобы уменьшить высоту и ширину размеров активации в 2 раза, можно использовать свертку 1x1 с шагом 2.\n",
    "* Слой CONV2D на пути быстрого доступа не использует никакой нелинейной функции активации. Его основная роль заключается в том, чтобы просто применить линейную функцию, которая уменьшает размерность входных данных, так что размеры совпадают для последующего шага сложения.\n",
    "\n",
    "Ключевые шаги следующие.\n",
    "\n",
    "Первый компонент - главный путь: \n",
    "- Первый CONV2D имеет $F_1$ фильтров размером (1,1) и шагом (s,s). Padding - \"valid\" и имя слоя корректно дать `conv_name_base + '2a'`.\n",
    "- BatchNorm - нормализация 'channels' размерности.  Имя слоя - `bn_name_base + '2a'`.\n",
    "- Затем ReLU activation function. Которая не имеет имя и гиперпараметры.\n",
    "\n",
    "Второй компонент - главный путь:\n",
    "- Второй CONV2D имеет $F_2$ фильтров размером $(f,f)$ и шагом (1,1).  Padding - \"same\" и имя слоя корректно дать `conv_name_base + '2b'`.\n",
    "- BatchNorm - нормализация 'channels' размерности.  Имя слоя - `bn_name_base + '2b'`.\n",
    "- Затем ReLU activation function. Которая не имеет имя и гиперпараметры. \n",
    "\n",
    "Третий компонент - главный путь:\n",
    "- Третий CONV2D имеет $F_3$ фильтров размером (1,1) и шагом (1,1). Padding - \"valid\" и имя слоя корректно дать `conv_name_base + '2c'`.\n",
    "- BatchNorm - нормализация 'channels' размерности.  Имя слоя - `bn_name_base + '2c'`. \n",
    "- **Нет** ReLU activation function в данном компоненте.\n",
    "\n",
    "Короткий путь:\n",
    "- CONV2D имеет $F_3$ фильтров размером (1,1) и шагом (s,s). adding - \"valid\" и имя слоя корректно дать `conv_name_base + '1'`.  Use 0 as the `glorot_uniform` seed.\n",
    "- The BatchNorm is normalizing the 'channels' axis.  Its name should be `bn_name_base + '1'`. \n",
    "\n",
    "Финальный шаг: \n",
    "- The shortcut and the main path values are added together.\n",
    "- Then apply the ReLU activation function. This has no name and no hyperparameters. \n",
    "    \n",
    "**Упражнение**: Implement the convolutional block. We have implemented the first component of the main path; you should implement the rest. As before, always use 0 as the seed for the random initialization, to ensure consistency with our grader.\n",
    "- [Conv2D](https://keras.io/layers/convolutional/#conv2d)\n",
    "- [BatchNormalization](https://keras.io/layers/normalization/#batchnormalization) (axis: Integer, the axis that should be normalized (typically the features axis))\n",
    "- For the activation, use:  `Activation('relu')(X)`\n",
    "- [Add](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convolutional_block\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = None\n",
    "    X = None\n",
    "    X = None\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = None\n",
    "    X = None\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = None\n",
    "    X_shortcut = None\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = None\n",
    "    X = None\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = convolutional_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **out**\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.09018463  1.23489773  0.46822017  0.0367176   0.          0.65516603]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Построение ResNet модели (50 слоёв)\n",
    "\n",
    "На следующем рисунке подробно описана архитектура этой нейронной сети. \"ID BLOCK\" на схеме означает \"Identity block\" и \"ID BLOCK x3\" означает, что вы должны объединить 3 тож блоков.\n",
    "\n",
    "<img src=\"images/resnet_kiank.png\" style=\"width:850px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Рисунок 5** </u><font color='purple'>  : **ResNet-50 model** </center></caption>\n",
    "\n",
    "Детальные шаги:\n",
    "- Zero-padding с размером (3,3)\n",
    "- Шаг 1:\n",
    "    - 2D Convolution имеют 64 филтров с размером (7,7) и использует шаг (2,2). Имя - \"conv1\".\n",
    "    - BatchNorm применяется к входным 'channels' в изображении.\n",
    "    - MaxPooling использует window размером (3,3) и (2,2) шагом.\n",
    "- Шаг 2:\n",
    "    - Сonvolutional block использует три набора фильтров с размером [64,64,256], \"f\" - 3, \"s\" - 1 и блок - \"a\".\n",
    "    - 2 identity blocks использует три набора фильтров с размером [64,64,256], \"f\" - 3 и блок - \"b\" и \"c\".\n",
    "- Шаг 3:\n",
    "    - Convolutional block использует три набора фильтров с размером [128,128,512], \"f\" - 3, \"s\" - 2 и блок - \"a\".\n",
    "    - 3 identity blocks использует три набора фильтров с размером [128,128,512], \"f\" - 3 и блок - \"b\", \"c\" and \"d\".\n",
    "- Шаг 4:\n",
    "    - Convolutional block использует три набора фильтров с размером [256, 256, 1024], \"f\" - 3, \"s\" - 2 и блок - \"a\".\n",
    "    - The 5 identity blocks использует три набора фильтров с размером [256, 256, 1024], \"f\" - 3 и блок - \"b\", \"c\", \"d\", \"e\" и \"f\".\n",
    "- Шаг 5:\n",
    "    - Convolutional block использует три набора фильтров с размером [512, 512, 2048], \"f\" - 3, \"s\" - 2 и блок - \"a\".\n",
    "    - 2 identity blocks использует три набора фильтров с размером [512, 512, 2048], \"f\" - 3 и блок - \"b\" и \"c\".\n",
    "- 2D Average Pooling использует окно с размером (2,2) и наименованием \"avg_pool\".\n",
    "- 'flatten' слой не имеет гиперпараметров и имени.\n",
    "- Fully Connected (Dense) слой уменьшается до количества классов. Его имя может быть `'fc' + str(classes)`.\n",
    "\n",
    "**Упражнение**: Реализовать ResNet с 50 слоями описанными на рисунке выше.\n",
    "\n",
    "Можно использовать следующие функции: \n",
    "- Average pooling [see reference](https://keras.io/layers/pooling/#averagepooling2d)\n",
    "- Conv2D: [See reference](https://keras.io/layers/convolutional/#conv2d)\n",
    "- BatchNorm: [See reference](https://keras.io/layers/normalization/#batchnormalization)\n",
    "- Zero padding: [See reference](https://keras.io/layers/convolutional/#zeropadding2d)\n",
    "- Max pooling: [See reference](https://keras.io/layers/pooling/#maxpooling2d)\n",
    "- Fully connected layer: [See reference](https://keras.io/layers/core/#dense)\n",
    "- Addition: [See reference](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: ResNet50\n",
    "\n",
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Реализовать архитектуру ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- размер входных изображений из датасета\n",
    "    classes -- integer, номер класса\n",
    "\n",
    "    Returns:\n",
    "    model -- Model() класс в Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # входной слой\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Шаг 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Шаг 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### НАЧАЛО ВАШЕГО КОДА ###\n",
    "\n",
    "    # Шаг 3 (≈4 строки кода)\n",
    "    X = None\n",
    "    X = None\n",
    "    X = None\n",
    "    X = None\n",
    "\n",
    "    # Шаг 4 (≈6 строки кода)\n",
    "    X = None\n",
    "    X = None\n",
    "    X = None\n",
    "    X = None\n",
    "    X = None\n",
    "    X = None\n",
    "\n",
    "    # Шаг 5 (≈3 строки кода)\n",
    "    X = None\n",
    "    X = None\n",
    "    X = None\n",
    "\n",
    "    # AVGPOOL (≈1 строка кода) - \"X = AveragePooling2D(...)(X)\"\n",
    "    X = None\n",
    "    \n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОДА ###\n",
    "\n",
    "    # выходной слой\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # создание модели\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель готова к обучению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка SIGNS Dataset.\n",
    "<img src=\"images/signs_data_kiank.png\" style=\"width:450px;height:250px;\">\n",
    "<caption><center> <u> <font color='purple'> **Рисунок 6** </u><font color='purple'>  : **SIGNS dataset** </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Нормализация\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Конвертирование меток в бинарный вектор\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs = 2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый выход**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            ** Epoch 1/2**\n",
    "        </td>\n",
    "        <td>\n",
    "           loss: между 1 и 5, acc: между 0.2 и 0.5.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            ** Epoch 2/2**\n",
    "        </td>\n",
    "        <td>\n",
    "           loss: между 1 и 5, acc: между 0.2 и 0.5.\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый выход**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Test Accuracy**\n",
    "        </td>\n",
    "        <td>\n",
    "           между 0.16 и 0.25\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим готовую - обученную специалистами модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./pretrain_model/ResNet50.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Тестирование со своими изображениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'images/my_image.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x/255.0\n",
    "print('Input image shape:', x.shape)\n",
    "my_image = scipy.misc.imread(img_path)\n",
    "imshow(my_image)\n",
    "print(\"class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \")\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что вы должны помнить\n",
    "- Очень глубокие \"простые\" сети не работают на практике, потому что их трудно обучить из-за исчезающих градиентов. \n",
    "- Пропуск-соединения помогают решить проблему исчезающего градиента.\n",
    "- Существует два основных типа блоков: блок идентификации и сверточный блок. \n",
    "- Очень глубокие остаточные сети строятся путем укладки этих блоков вместе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ссылки \n",
    "\n",
    "В этом notebook представлен алгоритм ResNet, разработанный He et al. (2015). Реализация приведена в репозитории GitHub Франсуа Шоле:\n",
    "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - [Deep Residual Learning for Image Recognition (2015)](https://arxiv.org/abs/1512.03385)\n",
    "- Francois Chollet's GitHub repository: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OEpi5",
   "launcher_item_id": "jK9EQ"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
