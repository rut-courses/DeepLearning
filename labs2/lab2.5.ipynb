{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Tutorial\n",
    "\n",
    "В предыдущих лабораторных работах вы всегда использовали numpy для построения нейронных сетей. Теперь мы изучим систему/фреймворк глубокого обучения, который позволит легче строить нейронные сети. Фреймворки машинного обучения, такие как TensorFlow, Torch, Caffe, Keras и многие другие, позволяют значительно ускорить развитие машинного обучения. Все эти фреймворки также имеют много документации, которую вы должны свободно читать. В этом задании вы научитесь делать следующее в TensorFlow:\n",
    "\n",
    "- Инициализация переменных\n",
    "- Запуск своей сессии\n",
    "- Реализация алгоритма обучения \n",
    "- Реализация нейронной сети\n",
    "\n",
    "Фреймворки программирования могут не только сократить время кодирования, но иногда также выполнять оптимизацию, которая ускоряет ваш код.\n",
    "\n",
    "## 1 - Изучение библиотеки Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда вы импортировали библиотеку, мы исследуем её различные приложения. Вы начнете с примера, где мы рассчитаем потерю на одном тренировочном примере. \n",
    "$$loss = \\mathcal{L}(\\hat{y}, y) = (\\hat y^{(i)} - y^{(i)})^2 \\tag{1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = tf.constant(36, name='y_hat')     # определим y_hat как константу. Установим в 36.\n",
    "y = tf.constant(39, name='y')             # определим y. Установим в 39\n",
    "\n",
    "loss = tf.Variable((y - y_hat)**2, name='loss')  # создадим переменную для расчёта потерь\n",
    "\n",
    "init = tf.global_variables_initializer()  # процесс инициализации запускается после определения всех переменных (session.run(init)),\n",
    "                                          # переменная потерь будет инициализирована и готова к вычислению\n",
    "with tf.Session() as session:             # Создайте сеанс и выведите выходные параметры\n",
    "    session.run(init)                     # инициализация переменных\n",
    "    print(session.run(loss))              # вывод потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написание и запуск программ на TensorFlow включает следующие шаги:\n",
    "\n",
    "1. Создание тензоров (переменных) которые еще не запущены/не вычислены.\n",
    "2. Запишите операции с этими тензорами.\n",
    "3. Инициализация тензоров. \n",
    "4. Создание сессии. \n",
    "5. Запуск сессии. Это позволит выполнить операции, которые вы реализовали ранее.\n",
    "\n",
    "Поэтому, когда мы создавали переменную для потери, мы просто определяли потерю как функцию от других величин, но не оценивали ее значение. Чтобы оценить его, мы должны были запустить `init = tf.global_variables_initializer()`. Это инициализировало переменную потерь, и в последней строке мы, наконец, смогли оценить значение `loss` и вывести значение.\n",
    "\n",
    "Теперь давайте рассмотрим простой пример. Запустите ячейку ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(10)\n",
    "c = tf.multiply(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, вы не увидите 20! Вы получили тензор, говорящий, что результатом является тензор, который не имеет атрибута shape и имеет тип \"int32\". Все, что вы сделали, было помещено в \"график вычислений\", но вы еще не выполнили это вычисление. Чтобы действительно умножить эти два числа, вам нужно будет создать сеанс и запустить его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Подводя итог, не забудьте инициализировать переменные, создать сеанс и запустить операции внутри сеанса. \n",
    "\n",
    "Далее, вы также должны знать о заполнителях (placeholders). placeholders - это объект, значение которого можно указать только позже. \n",
    "Чтобы указать значения для заполнителя, можно передать значения с помощью \"справочника каналов\" (переменная `feed_dict`). Ниже мы создали заполнитель для x. это позволяет нам передавать число позже, когда мы запускаем сеанс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменение x в feed_dict\n",
    "\n",
    "x = tf.placeholder(tf.int64, name = 'x')\n",
    "print(sess.run(2 * x, feed_dict = {x: 3}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда вы впервые определили `x`, вам не нужно было указывать для него значение. placeholder - это просто переменная, которой вы будете присваивать данные только позже, при запуске сеанса. Часто говорят, что **feed data** это заполнитель при запуске сеанса.\n",
    "\n",
    "Вот что происходит: когда вы указываете операции, необходимые для вычисления, вы говорите TensorFlow, как построить вычислительный граф. Граф вычислений может иметь некоторые заполнители, значения которых вы укажете только позже. Наконец, когда вы запускаете сеанс,вы говорите TensorFlow выполнить график вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Линейная функция\n",
    "\n",
    "Давайте начнем это упражнение с вычисления следующего уравнения: $Y = WX + b$, где $W$ и $X$ случайные матрицы и b вектор случайных значений. \n",
    "\n",
    "**Упражнение**: Вычислить $WX + b$ где $W, X$, и $b$ получаются из случайного нормального распределения. W размером (4, 3), X - (3,1) и b - (4,1). В качестве примера, вот как можно определить константу X, которая имеет форму (3,1):\n",
    "```python\n",
    "X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
    "```\n",
    "Возможно, вам помогут следующие функции: \n",
    "- tf.matmul(..., ...) перемножение матриц\n",
    "- tf.add(..., ...) сложение\n",
    "- np.random.randn(...) случайная инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: linear_function\n",
    "\n",
    "def linear_function():\n",
    "    \"\"\"\n",
    "    Реализация линейной функции: \n",
    "            инициализация W, который должен быть случайным тензором размером (4,3)\n",
    "            инициализация X, который должен быть случайным тензором размером (3,1)\n",
    "            инициализация b, который должен быть случайным тензором размером (4,1)\n",
    "    Returns: \n",
    "    result -- запуск сессии Y = WX + b \n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (4 строки кода)\n",
    "    X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
    "    W = tf.constant(np.random.randn(4,3), name = \"W\")\n",
    "    b = tf.constant(np.random.randn(4,1), name = \"b\")\n",
    "    Y = tf.add(tf.matmul(W, X), b)\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ### \n",
    "    \n",
    "    # Создание сессии с использованием tf.Session() и запуск с использованием sess.run(...)\n",
    "    \n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    sess = None\n",
    "    result = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ### \n",
    "    \n",
    "    # Закрытие сессии\n",
    "    sess.close()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"result = \" + str(linear_function()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Ожидаемый результат ***: \n",
    "\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "**result**\n",
    "</td>\n",
    "<td>\n",
    "[[-2.15657382]\n",
    " [ 2.95891446]\n",
    " [-1.08926781]\n",
    " [-0.84538042]]\n",
    "</td>\n",
    "</tr> \n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Вычисление sigmoid \n",
    "\n",
    "Отлично! Ранее вы реализовали линейную функцию. Tensorflow предлагает множество часто используемых функций нейронной сети, таких как `tf.sigmoid` и `tf.softmax`. Для этого упражнения вычислим сигмовидную функцию входного сигнала. \n",
    "\n",
    "Вы будете выполнять это упражнение, используя переменную-заполнитель `x`. При запуске сеанса вы должны использовать feed dictionary  для передачи входных данных `z`. В этом упражнении вам придется (1) создать placeholder `x`, (2) определить операции, необходимые для вычисления сигмоиды с помощью `tf.sigmoid`, а затем (3) запустить сеанс.\n",
    "\n",
    "** Упражнение **: Реализовать sigmoid function. Необходимо использовать следующее: \n",
    "\n",
    "- `tf.placeholder(tf.float32, name = \"...\")`\n",
    "- `tf.sigmoid(...)`\n",
    "- `sess.run(..., feed_dict = {x: z})`\n",
    "\n",
    "Обратите внимание, что существует два способа создания и использования сеансов в tensorflow:\n",
    "\n",
    "**Метод 1:**\n",
    "```python\n",
    "sess = tf.Session()\n",
    "# Запуск инициализации параметров (если необходимо), запуск операций\n",
    "result = sess.run(..., feed_dict = {...})\n",
    "sess.close() # закрытие сессии\n",
    "```\n",
    "**Метод 2:**\n",
    "```python\n",
    "with tf.Session() as sess: \n",
    "    # Запуск инициализации параметров (если необходимо), запуск операций\n",
    "    result = sess.run(..., feed_dict = {...})\n",
    "    # закрытие сессии произойдёт автоматически\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Вычисление sigmoid для z\n",
    "    \n",
    "    Arguments:\n",
    "    z -- входное значение, скаляр или вектор\n",
    "    \n",
    "    Returns: \n",
    "    results -- sigmoid по z\n",
    "    \"\"\"\n",
    "    \n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### ( ~ 4 строки кода)\n",
    "    # Создание placeholder для x. Название переменной - 'x'.\n",
    "    x = tf.placeholder(tf.float32, name='x')\n",
    "\n",
    "    # Вычисление sigmoid(x)\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "\n",
    "    # Создайте сеанс и запустите его. Используйте метод 2, описанный выше.\n",
    "    # Необходимо использовать feed_dict чтобы передать z значение в x. \n",
    "    with tf.Session() as sess: \n",
    "        result = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoid(15) = \" + str(sigmoid(15)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Ожидаемый результат ***: \n",
    "\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "**sigmoid(0)**\n",
    "</td>\n",
    "<td>\n",
    "0.5\n",
    "</td>\n",
    "</tr>\n",
    "<tr> \n",
    "<td>\n",
    "**sigmoid(12)**\n",
    "</td>\n",
    "<td>\n",
    "0.99999964\n",
    "</td>\n",
    "</tr> \n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**Что необходимо помнить**:\n",
    "\n",
    "1. Создание placeholders\n",
    "2. Укажите график вычислений, соответствующий операциям, которые вы хотите вычислить\n",
    "3. Создание сеанса\n",
    "4. Запустите сеанс, используя feed dictionary, если необходимо, чтобы указать значения переменных - заполнителей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 -  Вычисление потерь\n",
    "\n",
    "Вы также можете использовать встроенную функцию для вычисления потерь нейронной сети. Поэтому вместо того, чтобы писать код для вычисления этой функции для $a^{[2](i)}$ и $y^{(i)}$ по i=1...m: \n",
    "$$ J = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log a^{ [2] (i)} + (1-y^{(i)})\\log (1-a^{ [2] (i)} )\\large )\\small\\tag{1}$$\n",
    "\n",
    "вы можете сделать в одну строку кода в tensorflow!\n",
    "\n",
    "**Упражнение**: Реализуйте  функцию потерь кросс-энтропия. Функция, которую вы будете использовать, является: \n",
    "\n",
    "- `tf.nn.sigmoid_cross_entropy_with_logits(logits = ...,  labels = ...)`\n",
    "\n",
    "Ваш код на вход получает `z`, вычисляет sigmoid (получает `a`) и затем вычисляет потери с использование кросс-энтропии $J$. Все это можно сделать с помощью одного вызова `tf.nn.sigmoid_cross_entropy_with_logits`, которая вычисляет:\n",
    "\n",
    "$$- \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log \\sigma(z^{[2](i)}) + (1-y^{(i)})\\log (1-\\sigma(z^{[2](i)})\\large )\\small\\tag{2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: cost\n",
    "\n",
    "def cost(logits, labels):\n",
    "    \"\"\"\n",
    "    Вычисление потерь с использование сигмоиды и кросс-энтропии\n",
    "        \n",
    "    Arguments:\n",
    "    logits -- вектор, содержащий z, выход последнего линейного блока (перед функцией активацией)\n",
    "    labels -- вектор меток y (1 or 0) \n",
    "    \n",
    "    Примечание: то, что мы называем \"Z\" и \"Y\" в этом классе, соответственно, называется \"logits\" и \"labels\" в TensorFlow \n",
    "    документации. Поэтому logits будут поступать в z, а labels в Y.\n",
    "    \n",
    "    Returns:\n",
    "    cost -- запускает сеанс расчёта функции потерь (формула (2))\n",
    "    \"\"\"\n",
    "    \n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### \n",
    "    \n",
    "    # Создание  placeholders для \"logits\" (z) и \"labels\" (y) (~ 2 строки кода)\n",
    "    z = None\n",
    "    y = None\n",
    "    \n",
    "    # Использование функции потерь (~ 1 строка кода)\n",
    "    cost = None\n",
    "    \n",
    "    # Создание сессии (~ 1 строка кода).\n",
    "    sess = None\n",
    "    \n",
    "    # Запуск сессии (~ 1 строка кода).\n",
    "    cost = None\n",
    "    \n",
    "    # Закрытие сессии (~ 1 строка кода).\n",
    "    sess.close()\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = sigmoid(np.array([0.2,0.4,0.7,0.9]))\n",
    "cost = cost(logits, np.array([0,0,1,1]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Ожидаемый результат** : \n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **cost**\n",
    "        </td>\n",
    "        <td>\n",
    "        [ 1.00538719  1.03664088  0.41385433  0.39956614]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 - Реализация One Hot encodings\n",
    "\n",
    "Много раз в глубоком обучении вы будете иметь вектор y с числами в диапазоне от 0 до C-1, где C-количество классов. Если C, например, 4, то у вас может быть следующий вектор y, который вам нужно будет преобразовать следующим образом:\n",
    "\n",
    "<img src=\"images/onehot.png\" style=\"width:600px;height:150px;\">\n",
    "\n",
    "Это называется \"one hot\" кодировка, потому что в преобразованном представлении ровно один элемент каждого столбца является \"hot\" (то есть равным 1). Чтобы сделать это преобразование в numpy, вам, возможно, придется написать несколько строки кода. В tensorflow можно использовать одну строку кода:\n",
    "\n",
    "- tf.one_hot(labels, depth, axis) \n",
    "\n",
    "**Упражнение:** Реализуйте функцию ниже, чтобы взять один вектор меток и общее число классов $C$, и вернуть one hot encoding. Используйте `tf.one_hot()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: one_hot_matrix\n",
    "\n",
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Создание матрицы где i-я строка соответствует i-мк классу и j-й колонке соответствующий j-му обучающему примеру. Итак, если \n",
    "    пример j имеет метку i. \n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Тогда запись (i, j) будет равна 1.\n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- вектор меток \n",
    "    C -- количество классов\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot матрица\n",
    "    \"\"\"\n",
    "    \n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    # Создание a tf.constant равной C (глубина), 'C'. (~ 1 строка кода)\n",
    "    C = None\n",
    "    \n",
    "    # Use tf.one_hot (~ 1 строка кода)\n",
    "    one_hot_matrix = None\n",
    "    \n",
    "    # Создание сессии (~ 1 строка кода)\n",
    "    sess = None\n",
    "    \n",
    "    # Запуск сессии (~ 1 строка кода)\n",
    "    one_hot = None\n",
    "    \n",
    "    # Закрытие сессии (~ 1 line)\n",
    "    sess.close()\n",
    "    \n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**: \n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **one_hot**\n",
    "        </td>\n",
    "        <td>\n",
    "        [[ 0.  0.  0.  1.  0.  0.]\n",
    " [ 1.  0.  0.  0.  0.  1.]\n",
    " [ 0.  1.  0.  0.  1.  0.]\n",
    " [ 0.  0.  1.  0.  0.  0.]]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 - Инициализация нулями и единицами\n",
    "\n",
    "В данной части вы изучите как инициализировать вектор нулями и единицами. \n",
    "Функция инициализации единичной матрицы: `tf.ones()`. \n",
    "Функция инициализации матрицы нулей: `tf.zeros()`. \n",
    "Данные функции принимают на вход размер матриц, а на выходе получаются матрицы нулей и единиц соответственно.\n",
    "\n",
    "**Упражнение:** Реализуйте функцию ниже, чтобы принять размер и вернуть массив. \n",
    " - tf.ones(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: ones\n",
    "\n",
    "def ones(shape):\n",
    "    \"\"\"\n",
    "    Создание массива единиц с заданным размером\n",
    "    \n",
    "    Arguments:\n",
    "    shape -- размер массива, который вы хотите создать\n",
    "        \n",
    "    Returns: \n",
    "    ones -- массив, содержащий только единицы\n",
    "    \"\"\"\n",
    "    \n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    # Создание \"единичного\" тензора с использованием tf.ones(...). (~ 1 срока кода)\n",
    "    ones = None\n",
    "    \n",
    "    # Создание сессии (~ 1 срока кода)\n",
    "    sess = None\n",
    "    \n",
    "    # Запуск сессии (~ 1 срока кода)\n",
    "    ones = None\n",
    "    \n",
    "    # Закрытие сессии (~ 1 срока кода)\n",
    "    sess.close()\n",
    "    \n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    return ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"ones = \" + str(ones([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат:**\n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **ones**\n",
    "        </td>\n",
    "        <td>\n",
    "        [ 1.  1.  1.]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Построение нейронной сети с использованием tensorflow\n",
    "\n",
    "В данной части лабораторной работы необходимо построить нейронную сеть с использованием tensorflow. Помните, что существует две части для реализации модели:\n",
    "\n",
    "- Создание графа вычислений\n",
    "- Запуск графа вычислений\n",
    "\n",
    "### 2.0 - Постановка задачи: SIGNS Dataset\n",
    "\n",
    "Ваша задача-построить алгоритм, который облегчит общение человека с нарушениями речи с тем, кто не понимает язык жестов. \n",
    "\n",
    "- **Обучающий набор данных**: 1080 изображений (64 на 64 пикселей) знаков, представляющих числа с 0 до 5 (180 изображений на одно число).\n",
    "- **Тестовый набор данных**: 120 изображений (64 на 64 пикселей) знаков, представляющих числа с 0 до 5 (20 изображений на одно число).\n",
    "\n",
    "Обратите внимание, что это подмножество набора данных SIGNS dataset. Полный набор данных содержит гораздо больше знаков.\n",
    "\n",
    "Вот примеры для каждого числа, а также объяснение того, как представлены метки. Это исходные снимки, до снижения размерности изображения до 64 на 64 пикселя.\n",
    "\n",
    "<img src=\"images/hands.png\" style=\"width:800px;height:350px;\"><caption><center> <u><font color='purple'> **Рисунок 1**</u><font color='purple'>: SIGNS dataset <br> <font color='black'> </center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Измените индекс и запустите ячейку, чтобы визуализировать некоторые примеры в наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Примеры изображений\n",
    "index = 4\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как обычно, вы преобразуете в вектор набор данных изображений, а затем нормализуете его путем деления на 255. Кроме того, вы преобразуете каждую метку в один горячий вектор, как показано на Рис.1. Запустите ячейку ниже, чтобы сделать это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование в вектор матрицы изображений\n",
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "# Нормализация обучающего и тестового вектора\n",
    "X_train = X_train_flatten/255.\n",
    "X_test = X_test_flatten/255.\n",
    "# Конвертирование меток в One Hot матрицу\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
    "\n",
    "print (\"Количество обучающих примеров = \" + str(X_train.shape[1]))\n",
    "print (\"Количество тестовых примеров = \" + str(X_test.shape[1]))\n",
    "print (\"X_train размер: \" + str(X_train.shape))\n",
    "print (\"Y_train размер: \" + str(Y_train.shape))\n",
    "print (\"X_test размер: \" + str(X_test.shape))\n",
    "print (\"Y_test размер: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обратите внимание**, что 12288 происходит от $64 \\times 64 \\times 3$. Каждое изображение квадратное, 64 на 64 пикселя, и 3 для цветовых каналов - RGB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your goal** is to build an algorithm capable of recognizing a sign with high accuracy. To do so, you are going to build a tensorflow model that is almost the same as one you have previously built in numpy for cat recognition (but now using a softmax output). It is a great occasion to compare your numpy implementation to the tensorflow one. \n",
    "\n",
    "**Ваша цель** - построить алгоритм, способный распознавать знак с высокой точностью. Для этого необходимо построить модель с использованием tensorflow, которая почти совпадает с той, которую строилась ранее в numpy для распознавания кошек (но теперь в качестве выходной функцией активации используется - softmax). \n",
    "\n",
    "**Модель** - *LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX*. SIGMOID преобразован в SOFTMAX. SOFTMAX layer generalizes SIGMOID to when there are more than two classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Создание placeholders\n",
    "\n",
    "Ваша первая задача - создать placeholders для `X` и `Y`. Это позволит передавать обучающую выборку во время выполнения сеанса.\n",
    "\n",
    "**Упражнение:** Реализуйте функцию по созданию placeholders с использованием tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: create_placeholders\n",
    "\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Создание placeholders для tensorflow сессии.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- скаляр, размер входного вектора (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- sскаляр, количество классов (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder для входной матрицы признаков [n_x, None] и dtype \"float\"\n",
    "    Y -- placeholder для входных меток [n_y, None] и dtype \"float\"\n",
    "    \n",
    "    Подсказка:\n",
    "    - Необходимо использовать None, потому что это позволит быть гибкими в отношении количества примеров, которые необходимо \n",
    "    использовать для placeholder. На самом деле, количество примеров во время теста/обучения отличается\n",
    "    \"\"\"\n",
    "\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (~ 2 строки кода)\n",
    "    X = None\n",
    "    Y = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = create_placeholders(12288, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**: \n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **X**\n",
    "        </td>\n",
    "        <td>\n",
    "        Tensor(\"Placeholder_1:0\", shape=(12288, ?), dtype=float32) (not necessarily Placeholder_1)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr> \n",
    "        <td>\n",
    "            **Y**\n",
    "        </td>\n",
    "        <td>\n",
    "        Tensor(\"Placeholder_2:0\", shape=(10, ?), dtype=float32) (not necessarily Placeholder_2)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Инициализация параметров\n",
    "\n",
    "Следующая задача это инициализировать параметры с использованием tensorflow.\n",
    "\n",
    "**Упражнение:** Реализуйте функцию по инициализации параметров с использованием tensorflow. Необходимо использовать Xavier Initialization для весов и Zero Initialization для смещений. Формы приведены ниже. Пример для W1 и b1:\n",
    "\n",
    "```python\n",
    "W1 = tf.get_variable(\"W1\", [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "```\n",
    "Пожалуйста используйте `seed = 1`, тогда результаты будут совпадать с верными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Инициализируйте параметры для построения нейронной сети с использованием tensorflow. \n",
    "    Размер:\n",
    "            W1 : [25, 12288]\n",
    "            b1 : [25, 1]\n",
    "            W2 : [12, 25]\n",
    "            b2 : [12, 1]\n",
    "            W3 : [6, 12]\n",
    "            b3 : [6, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- словарь тензоров для: W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)\n",
    "        \n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (~ 6 строки кода)\n",
    "    W1 = None\n",
    "    b1 = None\n",
    "    W2 = None\n",
    "    b2 = None\n",
    "    W3 = None\n",
    "    b3 = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**: \n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **W1**\n",
    "        </td>\n",
    "        <td>\n",
    "         < tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref >\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr> \n",
    "        <td>\n",
    "            **b1**\n",
    "        </td>\n",
    "        <td>\n",
    "        < tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref >\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr> \n",
    "        <td>\n",
    "            **W2**\n",
    "        </td>\n",
    "        <td>\n",
    "        < tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref >\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr> \n",
    "        <td>\n",
    "            **b2**\n",
    "        </td>\n",
    "        <td>\n",
    "        < tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref >\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Прямое распространение с использованием tensorflow \n",
    "\n",
    "Теперь необходимо реализовать модуль прямого распространения с использованием tensorflow. Функция получает словарь параметров и совершит прямой проход. Функции, которые необходимо использовать:\n",
    "\n",
    "- `tf.add(...,...)`\n",
    "- `tf.matmul(...,...)`\n",
    "- `tf.nn.relu(...)` примените в качестве функции активации ReLU\n",
    "\n",
    "**Упражнение:** Реализуйте прямой проход по нейронной сети с использованием  tensorflow. Важно отметить, что прямое распространение останавливается на `z3`. Причина в том, что в tensorflow выход последнего линейного слоя задается как вход функции, вычисляющей потери. Поэтому вычисление `a3` не нужно!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (~ 5 строки кода)              # Numpy Equivalents:\n",
    "    Z1 = None                                            # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = None                                        # A1 = relu(Z1)\n",
    "    Z2 = None                                             # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = None                                      # A2 = relu(Z2)\n",
    "    Z3 = None                                              # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(12288, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    print(\"Z3 = \" + str(Z3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**: \n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **Z3**\n",
    "        </td>\n",
    "        <td>\n",
    "        Tensor(\"Add_2:0\", shape=(6, ?), dtype=float32)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that the forward propagation doesn't output any cache. You will understand why below, when we get to brackpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Вычисление потерь\n",
    "\n",
    "Как было замечено ранее, очень легко вычислить потери, используя:\n",
    "```python\n",
    "tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = ..., labels = ...))\n",
    "```\n",
    "**Упражнение**: Реализовать вычисление функции потерь. \n",
    "- Важно помнить что \"`logits`\" и \"`labels`\" будут на входе `tf.nn.softmax_cross_entropy_with_logits` с размером (number of examples, num_classes).\n",
    "- С другой стороны, `tf.reduce_mean` basically does the summation over the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНИВАЕМОЕ: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Вычисление потерь\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- выход прямого распространения (выход с последнего LINEAR слоя), размером (6, number of examples)\n",
    "    Y -- вектор меток placeholder, размером таким же как и Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - тензор потерь\n",
    "    \"\"\"\n",
    "    \n",
    "    # чтобы соответствовать требованию tensorflow для tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (1 line of code)\n",
    "    cost = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(12288, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**: \n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **cost**\n",
    "        </td>\n",
    "        <td>\n",
    "        Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Обратное распространение & обновление параметров\n",
    "\n",
    "Именно в данной части можно прочувствовать всё преимущество фреймворков. Всё обратное распространение и обновление параметров осуществляется в 1й строке кода.\n",
    "\n",
    "После того, как вы вычислите функцию затрат. Вы создадите объект \"`optimizer`\". Вы должны вызвать этот объект вместе со стоимостью при запуске tf.session. При вызове он выполнит оптимизацию по заданной стоимости с выбранным методом и скоростью обучения.\n",
    "\n",
    "Для примера, оптимизация с использованием градиентного спуска выглядит следующим образом:\n",
    "```python\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "```\n",
    "\n",
    "Чтобы реализовать оптимизацию необходимо сделать:\n",
    "```python\n",
    "_ , c = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "```\n",
    "\n",
    "Это вычисляет обратное распространение, проходя через граф tensorflow в обратном порядке. От потерь к входу.\n",
    "\n",
    "**Заметка** В коде вы часто может встретить знак `_` - переменная для хранения значений, которые нам не нужно будет использовать позже. Здесь `_` принимает оцененное значение `optimizer`, которое нам не нужно (а `c` = это значение `cost`) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 - Построение модели\n",
    "\n",
    "Далее необходимо собрать все части вместе\n",
    "\n",
    "**Упражнение:** Реализуйте модель. Необходимо вызывать функции, которые были реализованы ранее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Реализация 3-х слойной нейронной сети с использованием tensorflow: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- обучающая выборка (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- метки для обучения (output size = 6, number of training examples = 1080)\n",
    "    X_test -- тестовая выборка (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- метки для тестирования (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- скорость градиентного спуска\n",
    "    num_epochs -- количество эпох обучения\n",
    "    minibatch_size -- размер мини-пакета\n",
    "    print_cost -- вывод результатов каждые 100 эпох\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- параметры обученной модель, которые используются для предсказания.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # возможность повторного запуска модели без перезаписи переменных tf\n",
    "    tf.set_random_seed(1)\n",
    "    seed = 3\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : кол-во примеров в обучающем наборе)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []\n",
    "    \n",
    "    # Создание Placeholders размером (n_x, n_y)\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (1 строка кода)\n",
    "    X, Y = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "\n",
    "    # Инициализация параметров\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (1 строка кода)\n",
    "    parameters = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    # Прямое распространение: построение графа прямого распространения с использованием tensorflow\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (1 строка кода)\n",
    "    Z3 = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    # Функция потерь: добаление функции потерь в граф\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (1 строка кода)\n",
    "    cost = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    # Обратное распространение: определение функции оптимизации. Используется - AdamOptimizer.\n",
    "    ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (1 строка кода)\n",
    "    optimizer = None\n",
    "    ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "    \n",
    "    # Инициализация всех переменных\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Старт сессии с использованием tensorflow\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Запуск инициализации\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Начало обучения\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Определение потерь относительно эпохи\n",
    "            num_minibatches = int(m / minibatch_size) # кол-во мини-пакетов - minibatch_size в обучающей выборке\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # выбор мини-пакета\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # ВАЖНО: Строка, которая запускает граф для мини-пакета\n",
    "                # Запуск сессии вызовом \"optimizer\" и \"cost\", feedict должен содержать мини-пакет (X,Y).\n",
    "                ### НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ### (1 строка кода)\n",
    "                _ , minibatch_cost = None, None\n",
    "                ### ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Вывод в результатов обучения на каждой 100-й эпохе\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # построение графика потерь\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # сохранение параметров в переменной\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Параметры обучены!\")\n",
    "\n",
    "        # Вычисление predict\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Вычисление accuracy на тестовой выборке\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Запустите следующую ячейку, чтобы обучить вашу модель! Обучение может занимать около 5 минут. Ваша \"стоимость после эпохи 100\" должна быть 1.016458. Если это не так, не тратьте время; прервите обучение, нажав на квадрат (⬛) в верхней строке записной книжки, и попробуйте исправить свой код. Если это правильная стоимость, сделайте перерыв и вернитесь через 5 минут!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ожидаемый результат**:\n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **Train Accuracy**\n",
    "        </td>\n",
    "        <td>\n",
    "        0.999074\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr> \n",
    "        <td>\n",
    "            **Test Accuracy**\n",
    "        </td>\n",
    "        <td>\n",
    "        0.716667\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Прекрасно, ваш алгоритм может распознавать знаки, представляющие собой цифру от 0 до 5 с точность 71.7%.\n",
    "\n",
    "**Идеи**:\n",
    "\n",
    "- Ваша модель имеет слишком много параметров, поскольку хорошо описывает обучающую выборку. Однако, учитывая разницу между точностью на обучении и тесте, можно попытаться добавить регуляризацию L2 или dropout, чтобы уменьшить эффект переобучения.\n",
    "- Сессию можно себе представить как блока кода, производящий обучения модели. Каждый раз, когда вы запускаете сеанс на мини-пакете, модель обучается и обновляет параметры. В общей сложности вы создали и запустили большое количество сессий (1500 эпох), пока не получили хорошо обученную модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 - Тестирование на Ваших изображениях\n",
    "\n",
    "Теперь вы можете сфотографировать свою руку и увидеть результат работы модели:\n",
    "\n",
    "    1. Нажмите на \"File\" в верхней строке этой записной книжки, затем нажмите \"Open\".\n",
    "    2. Добавьте свое изображение в каталог этой записной книжки Jupyter, в папку \"images\"\n",
    "    3. Напишите имя вашего изображения в следующем блоке-кода\n",
    "    4. Запустите код и проверьте работу алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "## НАЧАЛО ВАШЕГО КОД ЗДЕСЬ ##\n",
    "my_image = \"thumbs_up.jpg\"\n",
    "## ОКОНЧАНИЕ ВАШЕГО КОД ЗДЕСЬ ##\n",
    "\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(64,64)).reshape((1, 64*64*3)).T\n",
    "my_image_prediction = predict(my_image, parameters)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"Predict: y = \" + str(np.squeeze(my_image_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You indeed deserved a \"thumbs-up\" although as you can see the algorithm seems to classify it incorrectly. The reason is that the training set doesn't contain any \"thumbs-up\", so the model doesn't know how to deal with it! We call that a \"mismatched data distribution\" and it is one of the various of the next course on \"Structuring Machine Learning Projects\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color='blue'>\n",
    "**Что необходимо помнить?**:\n",
    "\n",
    "- Tensorflow-это фреймоворк, используемый в глубоком обучении.\n",
    "- Два основных класса объектов в tensorflow - это тензоры и операторы. \n",
    "- При написании кода в tensorflow необходимо выполнить следующие действия:\n",
    "    - Создайте график, содержащий тензоры (Variables, Placeholders ...) и операции (tf.matmul, tf.add, ...)\n",
    "    - Создание сессии\n",
    "    - Инициализация сессии\n",
    "    - Запуск сессии для вычисление графа\n",
    "- Вы можете вычислить граф несколько раз, как вы видели в model()\n",
    "- Обратное распространение и оптимизация выполняется автоматически при запуске сессии на объекте \"optimizer\"."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "BFd89",
   "launcher_item_id": "AH2rK"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit11a3618b34274847beed16472d0ddb8c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
